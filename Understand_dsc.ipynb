{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T13:42:32.210951Z",
     "iopub.status.busy": "2024-02-28T13:42:32.210755Z",
     "iopub.status.idle": "2024-02-28T13:42:34.230156Z",
     "shell.execute_reply": "2024-02-28T13:42:34.229429Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/gwpy/time/__init__.py:36: UserWarning: Wswiglal-redir-stdio:\n",
      "\n",
      "SWIGLAL standard output/error redirection is enabled in IPython.\n",
      "This may lead to performance penalties. To disable locally, use:\n",
      "\n",
      "with lal.no_swig_redirect_standard_output_error():\n",
      "    ...\n",
      "\n",
      "To disable globally, use:\n",
      "\n",
      "lal.swig_redirect_standard_output_error(True)\n",
      "\n",
      "Note however that this will likely lead to error messages from\n",
      "LAL functions being either misdirected or lost when called from\n",
      "Jupyter notebooks.\n",
      "\n",
      "To suppress this warning, use:\n",
      "\n",
      "import warnings\n",
      "warnings.filterwarnings(\"ignore\", \"Wswiglal-redir-stdio\")\n",
      "import lal\n",
      "\n",
      "  from lal import LIGOTimeGPS\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from loguru import logger\n",
    "from gwpy import signal, timeseries\n",
    "\n",
    "\n",
    "from pygwb.notch import StochNotch, StochNotchList\n",
    "from pygwb.util import calc_bias\n",
    "from pygwb import baseline, parameters\n",
    "from pygwb.delta_sigma_cut import run_dsc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produce a $\\Delta\\sigma$ cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T13:42:34.233066Z",
     "iopub.status.busy": "2024-02-28T13:42:34.232803Z",
     "iopub.status.idle": "2024-02-28T13:42:34.236661Z",
     "shell.execute_reply": "2024-02-28T13:42:34.236107Z"
    }
   },
   "outputs": [],
   "source": [
    "def dsc_cut(\n",
    "    naive_sigma: np.ndarray,\n",
    "    slide_sigma: np.ndarray,\n",
    "    dsc: float = 0.2,\n",
    "    bf_ss: float = 1,\n",
    "    bf_ns: float = 1,\n",
    "):\n",
    "    dsigma = np.abs(slide_sigma * bf_ss - naive_sigma * bf_ns) / slide_sigma * bf_ss\n",
    "\n",
    "    return dsigma >= dsc, dsigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T13:42:34.238952Z",
     "iopub.status.busy": "2024-02-28T13:42:34.238750Z",
     "iopub.status.idle": "2024-02-28T13:42:34.241923Z",
     "shell.execute_reply": "2024-02-28T13:42:34.241308Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_Hf(freqs: np.ndarray, alpha: float = 0, fref: int = 20):\n",
    "    Hf = (freqs / fref) ** alpha\n",
    "    return Hf  # do for different power laws , take all badgps times from all alphas, multiple calls in main func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T13:42:34.244118Z",
     "iopub.status.busy": "2024-02-28T13:42:34.243913Z",
     "iopub.status.idle": "2024-02-28T13:42:34.247225Z",
     "shell.execute_reply": "2024-02-28T13:42:34.246676Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_sigma_alpha(sensitivity_integrand_with_Hf: np.ndarray):\n",
    "    sigma_alpha = np.sqrt(1 / np.sum(sensitivity_integrand_with_Hf))\n",
    "    return sigma_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T13:42:34.249502Z",
     "iopub.status.busy": "2024-02-28T13:42:34.249176Z",
     "iopub.status.idle": "2024-02-28T13:42:34.254699Z",
     "shell.execute_reply": "2024-02-28T13:42:34.254054Z"
    }
   },
   "outputs": [],
   "source": [
    "def WindowFactors(window1: np.ndarray, window2: np.ndarray):\n",
    "    N1 = len(window1)\n",
    "    N2 = len(window2)\n",
    "    Nred = np.gcd(N1, N2).astype(int)\n",
    "    indices1 = (np.array(range(0, Nred, 1)) * N1 / Nred).astype(int)\n",
    "    indices2 = (np.array(range(0, Nred, 1)) * N2 / Nred).astype(int)\n",
    "    window1red = window1[indices1]\n",
    "    window2red = window2[indices2]\n",
    "\n",
    "    # extract 1st and 2nd half of windows\n",
    "\n",
    "    cut = int(np.floor(Nred / 2))\n",
    "\n",
    "    firsthalf1 = window1red[0:cut]\n",
    "    secondhalf1 = window1red[cut:Nred]\n",
    "\n",
    "    firsthalf2 = window2red[0:cut]\n",
    "    secondhalf2 = window2red[cut:Nred]\n",
    "\n",
    "    # calculate window factors\n",
    "    w1w2bar = np.mean(window1red * window2red)\n",
    "    w1w2squaredbar = np.mean((window1red**2) * (window2red**2))\n",
    "    w1w2ovlsquaredbar = np.mean((firsthalf1 * secondhalf1) * (firsthalf2 * secondhalf2))\n",
    "\n",
    "    return w1w2bar, w1w2squaredbar, w1w2ovlsquaredbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T13:42:34.257096Z",
     "iopub.status.busy": "2024-02-28T13:42:34.256896Z",
     "iopub.status.idle": "2024-02-28T13:42:34.261372Z",
     "shell.execute_reply": "2024-02-28T13:42:34.260801Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_sens_integrand(\n",
    "    freq: np.ndarray,\n",
    "    P1: np.ndarray,\n",
    "    P2: np.ndarray,\n",
    "    window1: np.ndarray,\n",
    "    window2: np.ndarray,\n",
    "    delta_f: float,\n",
    "    orf: np.array,\n",
    "    T: int = 32,\n",
    "    H0: float = 67.9e3 / 3.086e22,\n",
    "):\n",
    "    w1w2bar, w1w2squaredbar, oo = WindowFactors(window1 = window1, window2 = window2)\n",
    "    S_alpha = 3 * H0**2 / (10 * np.pi**2) * 1.0 / freq**3\n",
    "    sigma_square_avg = (\n",
    "        (w1w2squaredbar / w1w2bar**2)\n",
    "        * 1\n",
    "        / (2 * T * delta_f)\n",
    "        * P1\n",
    "        * P2\n",
    "        / (orf**2.0 * S_alpha**2)\n",
    "    )\n",
    "\n",
    "    return sigma_square_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T13:42:34.263578Z",
     "iopub.status.busy": "2024-02-28T13:42:34.263379Z",
     "iopub.status.idle": "2024-02-28T13:42:34.267943Z",
     "shell.execute_reply": "2024-02-28T13:42:34.267394Z"
    }
   },
   "outputs": [],
   "source": [
    "def veto_lines(freqs: np.ndarray, lines: np.ndarray, df: float = 0):\n",
    "    nbins = len(freqs)\n",
    "    veto = np.zeros((nbins, 1), dtype=\"bool\")\n",
    "\n",
    "    if not len(lines):\n",
    "        return veto\n",
    "\n",
    "    fmins = lines[:, 0]\n",
    "    fmaxs = lines[:, 1]\n",
    "    for fbin in range(len(freqs)):\n",
    "        freq = freqs[fbin]\n",
    "        index = np.argwhere((freq >= (fmins - df)) & (freq <= fmaxs + df))\n",
    "        if index.size != 0:\n",
    "            veto[fbin] = True\n",
    "    return veto\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T13:42:34.270324Z",
     "iopub.status.busy": "2024-02-28T13:42:34.269941Z",
     "iopub.status.idle": "2024-02-28T13:42:34.281473Z",
     "shell.execute_reply": "2024-02-28T13:42:34.280890Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_dsc(\n",
    "    dsc: float,\n",
    "    segment_duration: int,\n",
    "    sampling_frequency: int,\n",
    "    psd1_naive: np.ndarray,\n",
    "    psd2_naive: np.ndarray,\n",
    "    psd1_slide: np.ndarray,\n",
    "    psd2_slide: np.ndarray,\n",
    "    alphas: np.ndarray,\n",
    "    orf: np.array,\n",
    "    notch_list_path: str = \"\",\n",
    "):\n",
    "    if notch_list_path:\n",
    "        lines_stochnotch = StochNotchList.load_from_file(f\"{notch_list_path}\")\n",
    "        lines = np.zeros((len(lines_stochnotch), 2))\n",
    "\n",
    "        for index, notch in enumerate(lines_stochnotch):\n",
    "            lines[index, 0] = lines_stochnotch[index].minimum_frequency\n",
    "            lines[index, 1] = lines_stochnotch[index].maximum_frequency\n",
    "    else:\n",
    "        lines = np.zeros((0, 2))\n",
    "\n",
    "    logger.info(\"Running delta sigma cut\")\n",
    "    nalphas = len(alphas)\n",
    "    times = np.array(psd1_naive.times)\n",
    "    ntimes = len(times)\n",
    "    df = psd1_naive.df.value\n",
    "    dt = psd1_naive.df.value ** (-1)\n",
    "    bf_ns = calc_bias(segmentDuration = segment_duration, deltaF = df, deltaT = dt, N_avg_segs=1)  # Naive estimate\n",
    "    bf_ss = calc_bias(segmentDuration = segment_duration, deltaF = df, deltaT = dt, N_avg_segs=2)  # Sliding estimate\n",
    "    freqs = np.array(psd1_naive.frequencies)\n",
    "    overall_cut = np.zeros((ntimes, 1), dtype=\"bool\")\n",
    "    cuts = np.zeros((nalphas, ntimes), dtype=\"bool\")\n",
    "    dsigmas = np.zeros((nalphas, ntimes), dtype=\"bool\")\n",
    "    veto = veto_lines(freqs = freqs, lines = lines)\n",
    "    keep = np.squeeze(~veto)\n",
    "\n",
    "    window1 = np.hanning(segment_duration * sampling_frequency)\n",
    "    window2 = window1\n",
    "    for alpha in range(nalphas):\n",
    "        Hf = calc_Hf(freqs = freqs, alpha = alphas[alpha])\n",
    "        cut = np.zeros((ntimes, 1), dtype=\"bool\")\n",
    "        dsigma = np.zeros((ntimes, 1), dtype=\"bool\")\n",
    "        for time in range(len(times)):\n",
    "            psd1_naive_time = psd1_naive[time, :]\n",
    "            psd1_slide_time = psd1_slide[time, :]\n",
    "            psd2_naive_time = psd2_naive[time, :]\n",
    "            psd2_slide_time = psd2_slide[time, :]\n",
    "\n",
    "            naive_sensitivity_integrand_with_Hf = (\n",
    "                calc_sens_integrand(\n",
    "                    freq = freqs, P1 = psd1_naive_time, P2 = psd2_naive_time, window1 = window1, window2 = window2, delta_f = df, orf = orf, T = dt\n",
    "                )\n",
    "                / Hf**2\n",
    "            )\n",
    "\n",
    "            slide_sensitivity_integrand_with_Hf = (\n",
    "                calc_sens_integrand(\n",
    "                    freq = freqs, P1 = psd1_slide_time, P2 = psd2_slide_time, window1 = window1, window2 = window2, delta_f = df, orf = orf, T = dt\n",
    "                )\n",
    "                / Hf**2\n",
    "            )\n",
    "            naive_sigma_alpha = calc_sigma_alpha(\n",
    "                sensitivity_integrand_with_Hf = naive_sensitivity_integrand_with_Hf[keep]\n",
    "            )\n",
    "            slide_sigma_alpha = calc_sigma_alpha(\n",
    "                sensitivity_integrand_with_Hf = slide_sensitivity_integrand_with_Hf[keep]\n",
    "            )\n",
    "\n",
    "            cut[time], dsigma [time] = dsc_cut(naive_sigma = naive_sigma_alpha, slide_sigma = slide_sigma_alpha, dsc = dsc, bf_ss = bf_ss, bf_ns = bf_ns)\n",
    "\n",
    "        cuts[alpha, :] = np.squeeze(cut)\n",
    "        dsigmas[alpha, :] = np.squeeze(dsigma)\n",
    "\n",
    "    for time in range(len(times)):\n",
    "        overall_cut[time] = any(cuts[:, time])\n",
    "\n",
    "    BadGPStimes = times[np.squeeze(overall_cut)]\n",
    "\n",
    "    return BadGPStimes, dsigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T13:42:34.283965Z",
     "iopub.status.busy": "2024-02-28T13:42:34.283542Z",
     "iopub.status.idle": "2024-02-28T13:42:34.290625Z",
     "shell.execute_reply": "2024-02-28T13:42:34.290097Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle_path = \"../test/test_data/naive_and_sliding_psds.pickle\"\n",
    "\n",
    "with open(pickle_path, \"rb\") as handle:\n",
    "    pickle_loaded = pickle.load(handle)\n",
    "\n",
    "naive_psd_1 = pickle_loaded[\"naive_psd_1\"]\n",
    "naive_psd_2 = pickle_loaded[\"naive_psd_2\"]\n",
    "avg_psd_1 = pickle_loaded[\"avg_psd_1\"]\n",
    "avg_psd_2 = pickle_loaded[\"avg_psd_2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T13:42:34.293091Z",
     "iopub.status.busy": "2024-02-28T13:42:34.292672Z",
     "iopub.status.idle": "2024-02-28T13:42:37.092216Z",
     "shell.execute_reply": "2024-02-28T13:42:37.091460Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-02-28 13:42:34.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrun_dsc\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mRunning delta sigma cut\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1.24764440e+09, 1.24764449e+09, 1.24764459e+09]),\n",
       " array([[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_dsc(\n",
    "    dsc = 0.2,\n",
    "    segment_duration = 192,\n",
    "    sampling_frequency = 4096,\n",
    "    psd1_naive = naive_psd_1,\n",
    "    psd2_naive = naive_psd_2,\n",
    "    psd1_slide = avg_psd_1,\n",
    "    psd2_slide = avg_psd_2,\n",
    "    alphas = [-5, 0, 3],\n",
    "    orf = np.array([1]),\n",
    "    notch_list_path = \"../test/test_data/Official_O3_HL_notchlist.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T13:42:37.095153Z",
     "iopub.status.busy": "2024-02-28T13:42:37.094665Z",
     "iopub.status.idle": "2024-02-28T13:42:37.099389Z",
     "shell.execute_reply": "2024-02-28T13:42:37.098756Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shift = 1\n",
    "a = np.array([1,2,3,4,5])\n",
    "np.roll(a,shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T13:42:37.101654Z",
     "iopub.status.busy": "2024-02-28T13:42:37.101455Z",
     "iopub.status.idle": "2024-02-28T13:42:37.105103Z",
     "shell.execute_reply": "2024-02-28T13:42:37.104591Z"
    }
   },
   "outputs": [],
   "source": [
    "from numpy.random import random\n",
    "def shift_timeseries(time_series_data: timeseries.TimeSeries, time_shift: int=0):\n",
    "    if time_shift > 0:\n",
    "        shifted_data = np.roll(time_series_data, shift)\n",
    "    return shifted_data\n",
    "\n",
    "t = timeseries.TimeSeries(random(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T13:42:37.107611Z",
     "iopub.status.busy": "2024-02-28T13:42:37.107235Z",
     "iopub.status.idle": "2024-02-28T13:42:37.112005Z",
     "shell.execute_reply": "2024-02-28T13:42:37.111384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$[0.31373317,~0.76230909,~0.020910006,~0.58825514,~0.48176435,~0.16966562,~0.58687714,~0.23191557,~0.51443502,~0.93661302] \\; \\mathrm{}$"
      ],
      "text/plain": [
       "<TimeSeries([0.31373317, 0.76230909, 0.02091001, 0.58825514,\n",
       "             0.48176435, 0.16966562, 0.58687714, 0.23191557,\n",
       "             0.51443502, 0.93661302]\n",
       "            unit=Unit(dimensionless),\n",
       "            t0=<Quantity 0. s>,\n",
       "            dt=<Quantity 1. s>,\n",
       "            name=None,\n",
       "            channel=None)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T13:42:37.114442Z",
     "iopub.status.busy": "2024-02-28T13:42:37.114064Z",
     "iopub.status.idle": "2024-02-28T13:42:37.119074Z",
     "shell.execute_reply": "2024-02-28T13:42:37.118433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$[0.93661302,~0.31373317,~0.76230909,~0.020910006,~0.58825514,~0.48176435,~0.16966562,~0.58687714,~0.23191557,~0.51443502] \\; \\mathrm{}$"
      ],
      "text/plain": [
       "<TimeSeries([0.93661302, 0.31373317, 0.76230909, 0.02091001,\n",
       "             0.58825514, 0.48176435, 0.16966562, 0.58687714,\n",
       "             0.23191557, 0.51443502]\n",
       "            unit=Unit(dimensionless),\n",
       "            t0=<Quantity 0. s>,\n",
       "            dt=<Quantity 1. s>,\n",
       "            name=None,\n",
       "            channel=None)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shift_timeseries(t, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T13:42:37.121456Z",
     "iopub.status.busy": "2024-02-28T13:42:37.121048Z",
     "iopub.status.idle": "2024-02-28T13:42:37.409980Z",
     "shell.execute_reply": "2024-02-28T13:42:37.409151Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../test/test_data/H1L1_1247644138-1247645038.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m pickle_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../test/test_data/H1L1_1247644138-1247645038.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpickle_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m      3\u001b[0m             pickle_loaded \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(handle)\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../test/test_data/H1L1_1247644138-1247645038.pickle'"
     ]
    }
   ],
   "source": [
    "pickle_path='../test/test_data/H1L1_1247644138-1247645038.pickle'\n",
    "with open(pickle_path, \"rb\") as handle:\n",
    "            pickle_loaded = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T13:42:37.412529Z",
     "iopub.status.busy": "2024-02-28T13:42:37.412321Z",
     "iopub.status.idle": "2024-02-28T13:42:37.506131Z",
     "shell.execute_reply": "2024-02-28T13:42:37.505583Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../test/test_data/H1L1_1247644138-1247645038.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pickled_base \u001b[38;5;241m=\u001b[39m \u001b[43mbaseline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBaseline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../test/test_data/H1L1_1247644138-1247645038.pickle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m pickled_ifo_1 \u001b[38;5;241m=\u001b[39m pickled_base\u001b[38;5;241m.\u001b[39minterferometer_1\n\u001b[1;32m      4\u001b[0m pickled_ifo_2 \u001b[38;5;241m=\u001b[39m pickled_base\u001b[38;5;241m.\u001b[39minterferometer_2\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/pygwb/baseline.py:834\u001b[0m, in \u001b[0;36mBaseline.load_from_pickle\u001b[0;34m(cls, filename)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_pickle\u001b[39m(\u001b[38;5;28mcls\u001b[39m, filename):\n\u001b[1;32m    819\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    820\u001b[0m \u001b[38;5;124;03m    Load baseline object from pickle file.\u001b[39;00m\n\u001b[1;32m    821\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;124;03m        Baseline class.\u001b[39;00m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 834\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    835\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../test/test_data/H1L1_1247644138-1247645038.pickle'"
     ]
    }
   ],
   "source": [
    "pickled_base = baseline.Baseline.load_from_pickle(\"../test/test_data/H1L1_1247644138-1247645038.pickle\"\n",
    "        )\n",
    "pickled_ifo_1 = pickled_base.interferometer_1\n",
    "pickled_ifo_2 = pickled_base.interferometer_2\n",
    "naive_psd_1 = pickled_ifo_1.psd_spectrogram\n",
    "naive_psd_2 = pickled_ifo_2.psd_spectrogram\n",
    "avg_psd_1 = pickled_ifo_1.average_psd\n",
    "avg_psd_2 = pickled_ifo_2.average_psd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
