{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integration test with O3 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "printint = np.vectorize(np.int)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "stochastic_mat = loadmat('/home/shivaraj.kandhasamy/stochastic/iso/misc/pyGWB/command/stochData_gwosc.mat',struct_as_record=False, squeeze_me=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis parameters\n",
    "IFO1 = 'H1'\n",
    "IFO2 = 'L1'\n",
    "t0 = 1247644138 # start GPS time\n",
    "tf = 1247645038 # end GPS time\n",
    "data_type='public' # private -> running on LIGO data grid\n",
    "channel_suffix = 'GWOSC-16KHZ_R1_STRAIN' # detector name will be added later\n",
    "new_sample_rate = 4096 # sampled rate after resampling\n",
    "cutoff_frequency = 11 # high pass filter cutoff frequency\n",
    "segment_duration = 192 # also fftlength in pre-processing\n",
    "number_cropped_seconds = 2 # no. of secs to crop after highpass and resampling (default = 2 sec)\n",
    "window_downsampling = \"hamming\" # filter used for downsampling (default = 'hamming')\n",
    "ftype = \"fir\" # filter type used for downsampling\n",
    "window_fftgram = \"hann\" # window used for fft (used CSD and PSD estimation)\n",
    "overlap = segment_duration/2 # overlapping between segments\n",
    "frequency_resolution = 1.0/32 # final frequency resolution of CSD and PSD \n",
    "polarization = 'tensor' # for regular analysis \n",
    "alpha = 0 # power law index\n",
    "fref = 25 # Hz\n",
    "flow = 20 # Hz\n",
    "fhigh = 1726 # Hz\n",
    "coarse_grain = 0  # 0 - pwelch PSD estimate; 1 - corase-grain PSD estimate \n",
    "if coarse_grain:\n",
    "    fft_length = segment_duration\n",
    "else:\n",
    "    fft_length = int(1/frequency_resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from public server and apply HP filter and downsample or HP filtered and downsampled data from matlab\n",
    "# False - data from public server, True - data and ORF from matlab (for apple-to-apple comparison)\n",
    "apple_to_apple = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data and pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygwb import preprocessing\n",
    "from gwpy import timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not apple_to_apple:\n",
    "    \n",
    "    time_series_data1 = preprocessing.preprocessing_data_channel_name(IFO1,\n",
    "                                                t0,\n",
    "                                                tf,\n",
    "                                                data_type,\n",
    "                                                IFO1+':'+channel_suffix,\n",
    "                                                new_sample_rate,\n",
    "                                                cutoff_frequency,\n",
    "                                                segment_duration,\n",
    "                                                number_cropped_seconds=2,\n",
    "                                                window_downsampling=\"hamming\",\n",
    "                                                ftype=\"fir\",\n",
    "                                                )\n",
    "    \n",
    "    time_series_data2 = preprocessing.preprocessing_data_channel_name(IFO2,\n",
    "                                                t0,\n",
    "                                                tf,\n",
    "                                                data_type,\n",
    "                                                IFO2+':'+channel_suffix,\n",
    "                                                new_sample_rate,\n",
    "                                                cutoff_frequency,\n",
    "                                                segment_duration,\n",
    "                                                number_cropped_seconds=2,\n",
    "                                                window_downsampling=\"hamming\",\n",
    "                                                ftype=\"fir\",\n",
    "                                                )\n",
    "\n",
    "else:\n",
    "    \n",
    "    time_series_data1 =  timeseries.TimeSeries(stochastic_mat['finaltimeseries1'], t0=1247644204, sample_rate=4096)\n",
    "    time_series_data2 =  timeseries.TimeSeries(stochastic_mat['finaltimeseries2'], t0=1247644204, sample_rate=4096)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make PSDs and CSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygwb import spectral\n",
    "from pygwb.util import window_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_psd_1 = spectral.power_spectral_density(time_series_data1, segment_duration, frequency_resolution, window_fftgram= 'hann', overlap_factor=0.5)\n",
    "# adjacent averaged PSDs (detector 1) for each possible CSD\n",
    "avg_psd_1 = spectral.before_after_average(naive_psd_1, segment_duration, 2)\n",
    "\n",
    "naive_psd_2 = spectral.power_spectral_density(time_series_data2, segment_duration, frequency_resolution, window_fftgram= 'hann', overlap_factor=0.5)\n",
    "# adjacent averaged PSDs (detector 2) for each possible CSD\n",
    "avg_psd_2 = spectral.before_after_average(naive_psd_2, segment_duration, 2)\n",
    "\n",
    "# calcaulate CSD\n",
    "csd = spectral.cross_spectral_density(time_series_data1, time_series_data2, segment_duration, \n",
    "                                        frequency_resolution, overlap_factor=0.5, zeropad=True, window_fftgram='hann')\n",
    "                                           \n",
    "# remove edge segments from navie PSDs and CSDs to match with average PSDs\n",
    "stride = segment_duration - overlap\n",
    "ind_edge_segments = int(np.ceil(segment_duration / stride))\n",
    "\n",
    "csd = csd[ind_edge_segments:-(ind_edge_segments+1) + 1]\n",
    "\n",
    "# also remove naive psds from edge segments\n",
    "naive_psd_1 = naive_psd_1[ind_edge_segments:-(ind_edge_segments+1) + 1]\n",
    "naive_psd_2 = naive_psd_2[ind_edge_segments:-(ind_edge_segments+1) + 1]\n",
    "\n",
    "segment_starttime = csd.times.value # for later use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate ORF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygwb import orfs\n",
    "import bilby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate ORF\n",
    "interferometer_1 = bilby.gw.detector.get_empty_interferometer(IFO1)\n",
    "interferometer_2 = bilby.gw.detector.get_empty_interferometer(IFO2)\n",
    "if coarse_grain:\n",
    "    freqs = np.arange(0, len(stochastic_mat['gamma']))*frequency_resolution\n",
    "else:\n",
    "    freqs = avg_psd_1.yindex.value\n",
    "orf = orfs.calc_orf(\n",
    "                    freqs,\n",
    "                    interferometer_1.vertex,\n",
    "                    interferometer_2.vertex,\n",
    "                    interferometer_1.x,\n",
    "                    interferometer_2.x,\n",
    "                    interferometer_1.y,\n",
    "                    interferometer_2.y,\n",
    "                    polarization=polarization,\n",
    "                    )\n",
    "    \n",
    "deltaF = freqs[1]-freqs[0]\n",
    "try:\n",
    "    assert abs(deltaF - frequency_resolution) < 1e-6 # within machine (floating point) precision\n",
    "except ValueError:  \n",
    "    print('Frequency resolution in PSD/CSD is different than requested.')\n",
    "if apple_to_apple:\n",
    "    orf = stochastic_mat['gamma']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Band limiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_band_cut = (freqs>=flow) & (freqs<=fhigh)\n",
    "freqs = freqs[freq_band_cut]\n",
    "naive_psd_1 = naive_psd_1.crop_frequencies(flow, fhigh+deltaF)\n",
    "naive_psd_2 = naive_psd_2.crop_frequencies(flow, fhigh+deltaF)\n",
    "avg_psd_1 = avg_psd_1.crop_frequencies(flow, fhigh+deltaF)\n",
    "avg_psd_2 = avg_psd_2.crop_frequencies(flow, fhigh+deltaF)\n",
    "csd = csd.crop_frequencies(flow, fhigh+deltaF)\n",
    "orf = orf[freq_band_cut]\n",
    "stochastic_mat['gamma'] = stochastic_mat['gamma'][freq_band_cut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take CSD from matlab to see if there are any differences between coarsegraining function in matlab and pyGWB\n",
    "from pygwb.util import window_factors\n",
    "from gwpy.spectrogram import Spectrogram\n",
    "if apple_to_apple:\n",
    "    cc = np.zeros((len(csd),len(freqs)),dtype=complex)\n",
    "    cc[0,:] = stochastic_mat[\"rrCG\"][0].data\n",
    "    cc[1,:] = stochastic_mat[\"rrCG\"][1].data\n",
    "    cc[2,:] = stochastic_mat[\"rrCG\"][2].data\n",
    "    csd = Spectrogram(cc, times=csd.xindex.value, frequencies=csd.yindex.value)\n",
    "    w1w2bar, w1w2squaredbar, _, _ = window_factors(4096*192)\n",
    "    const =  new_sample_rate / (w1w2bar * 4096*192)\n",
    "    csd = 2* const * csd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate Y and sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygwb.constants import H0\n",
    "from pygwb.constants import speed_of_light\n",
    "from pygwb.util import window_factors\n",
    "\n",
    "# window factors\n",
    "w1w2bar, w1w2squaredbar, _, _ = window_factors(4096*192)\n",
    "\n",
    "def calculate_Yf_varf(freqs, csd, avg_psd_1, avg_psd_2, orf, fref, alpha,):    \n",
    "    S_alpha = 3 * H0**2 / (10 * np.pi**2) / freqs**3 * (freqs/fref)**alpha\n",
    "    Y_fs = np.real(csd)/(orf * S_alpha)\n",
    "    var_fs = 1 / (2 * segment_duration * (freqs[1]-freqs[0])) * avg_psd_1 * avg_psd_2 / (orf**2 * S_alpha**2)\n",
    "    var_fs = var_fs * w1w2squaredbar / w1w2bar ** 2\n",
    "    return Y_fs, var_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Y_f and sigma_f of stochastic analysis for every segment\n",
    "Y_fs, var_fs = calculate_Yf_varf(freqs, csd.value, \n",
    "                                   avg_psd_1.value, \n",
    "                                   avg_psd_2.value, \n",
    "                                   orf, fref, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency cuts/notches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notch_freq = np.real(stochastic_mat['ptEst_ff']==0)\n",
    "Y_fs[:,notch_freq] = 0\n",
    "var_fs[:,notch_freq] = np.Inf # some large number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make final point estimate and error bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygwb import postprocessing\n",
    "iso_job = postprocessing.IsotropicJob(Y_fs, (var_fs)**0.5, segment_starttime, segment_duration, new_sample_rate, frequencies=freqs)\n",
    "Y_f = iso_job.combined_Y_spectrum\n",
    "var_f = iso_job.combined_sigma_spectrum**2\n",
    "Y_pyGWB, sigma_pyGWB = iso_job.calculate_broadband_statistics(0) # alpha = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post-processing using modified expressions compared to Pat's\n",
    "from pygwb.util import calc_bias\n",
    "\n",
    "def postprocess_Y_sigma(Y_fs, var_fs):\n",
    "    size = np.size(Y_fs, axis=0)\n",
    "    _, w1w2squaredbar, _, w1w2squaredovlbar = window_factors(192*4096)\n",
    "    k = (w1w2squaredovlbar / w1w2squaredbar)\n",
    "\n",
    "    # even/odd indices\n",
    "    evens = np.arange(0, size, 2)\n",
    "    odds = np.arange(1, size, 2)\n",
    "\n",
    "    X_even = np.nansum(Y_fs[evens] / var_fs[evens], axis=0)\n",
    "    GAMMA_even = np.nansum(var_fs[evens] ** -1, axis=0)\n",
    "    X_odd = np.nansum(Y_fs[odds] / var_fs[odds], axis=0)\n",
    "    GAMMA_odd = np.nansum(var_fs[odds] ** -1, axis=0)  \n",
    "    sigma2_oo = 1/np.nansum(GAMMA_odd)\n",
    "    sigma2_ee = 1/np.nansum(GAMMA_even)\n",
    "    sigma2_1 = 1/np.nansum(var_fs[0,:] ** -1)\n",
    "    sigma2_N = 1/np.nansum(var_fs[-1,:] ** -1)\n",
    "    sigma2IJ = (1/sigma2_oo + 1/sigma2_ee - (1/2) * (1/sigma2_1+1/sigma2_N))\n",
    "\n",
    "\n",
    "    Y_f_new = (X_odd * (1- (k/2) * sigma2_oo * sigma2IJ) + X_even * (1- (k/2) * sigma2_ee * sigma2IJ))/ (\n",
    "            GAMMA_even + GAMMA_odd - k * (GAMMA_even + GAMMA_odd - (1/2) * (1/var_fs[0,:] + 1/var_fs[-1,:])))\n",
    "\n",
    "    inv_var_f_new = (GAMMA_odd + GAMMA_even - k * (GAMMA_odd + GAMMA_even - (1/2) * (1/var_fs[0,:] + 1/var_fs[-1,:]))) / (\n",
    "            1- (k**2 /4) * sigma2_oo * sigma2_ee * sigma2IJ**2)\n",
    "    bias = calc_bias(segment_duration, deltaF, 1 / new_sample_rate)\n",
    "    var_f_new = (1 / inv_var_f_new) * bias**2\n",
    "    var_f_new[notch_freq] = np.inf\n",
    "    Y_f_new[notch_freq] = 0\n",
    "    return Y_f_new, var_f_new\n",
    "\n",
    "\n",
    "Y_f_new, var_f_new = postprocess_Y_sigma(Y_fs, var_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_f = Y_f_new\n",
    "var_f = var_f_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with Matlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printint = np.vectorize(np.int)\n",
    "print('Segment start times from Matlab: ' + str(stochastic_mat['segmentStartTime']))\n",
    "print('Segment start times from pyGWB: ' + str(printint(segment_starttime)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(freqs, orf,label='pyGWB')\n",
    "plt.plot(freqs, stochastic_mat['gamma'],label='matlab')\n",
    "plt.title('Overlap reduction function')\n",
    "plt.xlim([flow, 1726])\n",
    "plt.xscale('linear')\n",
    "plt.ylabel('ORF')\n",
    "plt.ylim([-1,0.4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(freqs, abs(orf)/abs(stochastic_mat['gamma']))\n",
    "plt.title('Overlap reduction function')\n",
    "plt.xlim([flow, fhigh])\n",
    "plt.xscale('linear')\n",
    "plt.ylabel('pyGWB/matlab')\n",
    "plt.ylim([0,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(stochastic_mat['freq'], stochastic_mat['calPSD1_avg'][0].data,label='matlab')\n",
    "plt.loglog(stochastic_mat['freq'], avg_psd_1[0].value,label='pyGWB')\n",
    "plt.loglog(stochastic_mat['freq'],abs(stochastic_mat['calPSD1_avg'][0].data-avg_psd_1[0].value),label='difference')\n",
    "plt.xlim([flow, fhigh])\n",
    "plt.ylabel('avg PSD_1')\n",
    "plt.ylim([1e-48,1e-41])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(stochastic_mat['freq'], avg_psd_1[0].value/stochastic_mat['calPSD1_avg'][0].data)\n",
    "plt.xlim([flow, fhigh])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(stochastic_mat['freq'], stochastic_mat['calPSD2_avg'][0].data,label='matlab')\n",
    "plt.loglog(stochastic_mat['freq'], avg_psd_2[0].value,label='pyGWB')\n",
    "plt.loglog(stochastic_mat['freq'],abs(stochastic_mat['calPSD2_avg'][0].data-avg_psd_2[0].value),label='difference')\n",
    "plt.xlim([flow, fhigh])\n",
    "plt.ylabel('avg PSD_2')\n",
    "plt.ylim([1e-48,1e-41])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(stochastic_mat['freq'], avg_psd_2[0].value/stochastic_mat['calPSD2_avg'][0].data)\n",
    "plt.xlim([flow, fhigh])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(stochastic_mat['freq'], stochastic_mat['calPSD2_avg'][0].data,label='matlab')\n",
    "plt.xlim([flow, fhigh])\n",
    "plt.ylabel('avg PSD_2')\n",
    "plt.ylim([1e-48,1e-41])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(stochastic_mat['freq'], avg_psd_2[0].value,label='pyGWB')\n",
    "plt.xlim([flow, fhigh])\n",
    "plt.ylabel('avg PSD_2')\n",
    "#plt.ylim([1e-48,1e-41])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(stochastic_mat['freq'], np.real(Y_f),label='pyGWB (Pats post-process)')\n",
    "plt.plot(stochastic_mat['freq'], np.real(stochastic_mat['ptEst_ff']),label='matlab')\n",
    "plt.xlim([flow, fhigh])\n",
    "plt.ylabel('Y_f')\n",
    "plt.ylim([-1,1])\n",
    "plt.xlim([420, 425])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_f_matlab = np.real(stochastic_mat['ptEst_ff'])\n",
    "plt.plot(stochastic_mat['freq'], Y_f/Y_f_matlab, label='(Pats post-process)')\n",
    "plt.xlim(flow, fhigh)\n",
    "plt.ylabel('Y_f ratio')\n",
    "plt.ylim([-10, 10])\n",
    "plt.xlim(20,1726)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(stochastic_mat['freq'], np.real(Y_f_new),label='pyGWB (modified post-process)')\n",
    "plt.plot(stochastic_mat['freq'], np.real(stochastic_mat['ptEst_ff']),label='matlab')\n",
    "plt.xlim([flow, fhigh])\n",
    "plt.ylabel('Y_f')\n",
    "plt.ylim([-1,1])\n",
    "plt.xlim([420, 425])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_f_matlab = np.real(stochastic_mat['ptEst_ff'])\n",
    "plt.plot(stochastic_mat['freq'], Y_f_new/Y_f_matlab, label='(Modified post-process)')\n",
    "plt.xlim(flow, fhigh)\n",
    "plt.ylabel('Y_f ratio')\n",
    "plt.ylim([-1e-4+1, 1e-4+1])\n",
    "plt.xlim(20,1726)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_f[notch_freq] = np.inf\n",
    "plt.loglog(freqs, np.sqrt(var_f),label='pyGWB (Pats post-process)')\n",
    "plt.loglog(freqs, np.real(stochastic_mat['sigma_ff']),label='matlab')\n",
    "plt.xlim([flow, fhigh])\n",
    "plt.ylabel('sigma_f')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(freqs, np.sqrt(var_f)/np.real(stochastic_mat['sigma_ff']))\n",
    "plt.ylim(0.9, 1.1)\n",
    "plt.xlim([flow, fhigh])\n",
    "plt.ylabel('sigma_f ratio')\n",
    "plt.xlim([20, 1726])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_f_new[notch_freq] = np.inf\n",
    "plt.loglog(freqs, np.sqrt(var_f_new),label='pyGWB (Modified post-process)')\n",
    "plt.loglog(freqs, np.real(stochastic_mat['sigma_ff']),label='matlab')\n",
    "plt.xlim([flow, fhigh])\n",
    "plt.ylabel('sigma_f')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(freqs, np.sqrt(var_f_new)/np.real(stochastic_mat['sigma_ff']), label='(Modified post-process)' )\n",
    "plt.ylim(-1e-1+1, 1+1e-1)\n",
    "plt.xlim([flow, fhigh])\n",
    "plt.ylabel('sigma_f ratio')\n",
    "plt.xlim([20, 1726])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygwb.util import calc_Y_sigma_from_Yf_varf\n",
    "Y_maltab, sigma_matlab = calc_Y_sigma_from_Yf_varf(np.real(stochastic_mat['ptEst_ff']), stochastic_mat['sigma_ff']**2, freqs, alpha, fref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pyGWB_new, sigma_pyGWB_new = calc_Y_sigma_from_Yf_varf(Y_f_new, var_f_new, freqs, alpha, fref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Comparing point estimates')\n",
    "print('\\tstochastic.m: %e'%(Y_maltab))\n",
    "print('\\tpyGWB (Pats post-process): %e'%(Y_pyGWB))\n",
    "print('\\t%% diff: %f%%'%(100*abs((Y_pyGWB-Y_maltab)/Y_maltab)))\n",
    "\n",
    "print('Comparing sigmas')\n",
    "print('\\tstochastic.m: %e'%(sigma_matlab))\n",
    "print('\\tpyGWB (Pats post-process): %e'%(sigma_pyGWB))\n",
    "print('\\t%% diff: %f%%'%(100*abs((sigma_pyGWB-sigma_matlab)/sigma_matlab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Comparing point estimates')\n",
    "print('\\tstochastic.m: %e'%(Y_maltab))\n",
    "print('\\tpyGWB (modified post-process): %e'%(Y_pyGWB_new))\n",
    "print('\\t%% diff: %f%%'%(100*abs((Y_pyGWB_new-Y_maltab)/Y_maltab)))\n",
    "\n",
    "print('Comparing sigmas')\n",
    "print('\\tstochastic.m: %e'%(sigma_matlab))\n",
    "print('\\tpyGWB (modified post-process): %e'%(sigma_pyGWB_new))\n",
    "print('\\t%% diff: %f%%'%(100*abs((sigma_pyGWB_new-sigma_matlab)/sigma_matlab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}