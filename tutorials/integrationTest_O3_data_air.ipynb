{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygwb.detector import Interferometer\n",
    "from pygwb import network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis parameters\n",
    "t0 = 1247644138 # start GPS time\n",
    "tf = 1247645038 # end GPS time\n",
    "data_type='public' # private -> running on LIGO data grid\n",
    "channel_suffix = 'GWOSC-16KHZ_R1_STRAIN' # detector name will be added later\n",
    "new_sample_rate = 4096 # sampled rate after resampling\n",
    "cutoff_frequency = 11 # high pass filter cutoff frequency\n",
    "segment_duration = 192 # also fftlength in pre-processing\n",
    "number_cropped_seconds = 2 # no. of secs to crop after highpass and resampling (default = 2 sec)\n",
    "window_downsampling = \"hamming\" # filter used for downsampling (default = 'hamming')\n",
    "ftype = \"fir\" # filter type used for downsampling\n",
    "window_fftgram = \"hann\" # window used for fft (used CSD and PSD estimation)\n",
    "overlap = segment_duration/2 # overlapping between segments\n",
    "frequency_resolution = 1.0/32 # final frequency resolution of CSD and PSD \n",
    "polarization = 'tensor' # for regular analysis \n",
    "alpha = 0 # power law index\n",
    "fref = 25 # Hz\n",
    "flow = 20 # Hz\n",
    "fhigh = 1726 # Hz\n",
    "coarse_grain = 0  # 0 - pwelch PSD estimate; 1 - corase-grain PSD estimate \n",
    "if coarse_grain:\n",
    "    fft_length = segment_duration\n",
    "else:\n",
    "    fft_length = int(1/frequency_resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create IFO objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bilby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifo_H1 = Interferometer.get_empty_interferometer('H1')\n",
    "ifo_L1 = Interferometer.get_empty_interferometer('L1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data and pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygwb import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifo_H1.set_pre_processed_timeseries_from_channel_name(\n",
    "    ifo_H1.name,\n",
    "    t0,\n",
    "    tf,\n",
    "    data_type,\n",
    "    ifo_H1.name+':'+channel_suffix,\n",
    "    new_sample_rate,\n",
    "    cutoff_frequency,\n",
    "    segment_duration,\n",
    "    number_cropped_seconds=number_cropped_seconds,\n",
    "    window_downsampling=window_downsampling,\n",
    "    ftype=ftype,\n",
    ")\n",
    "\n",
    "ifo_L1.set_pre_processed_timeseries_from_channel_name(\n",
    "    ifo_L1.name,\n",
    "    t0,\n",
    "    tf,\n",
    "    data_type,\n",
    "    ifo_L1.name+':'+channel_suffix,\n",
    "    new_sample_rate,\n",
    "    cutoff_frequency,\n",
    "    segment_duration,\n",
    "    number_cropped_seconds=number_cropped_seconds,\n",
    "    window_downsampling=window_downsampling,\n",
    "    ftype=ftype,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# initialise a baseline with the new ifos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygwb.baseline import Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_HL = Baseline('HL', ifo_H1, ifo_L1, duration=segment_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make PSDs and CSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygwb import spectral\n",
    "from pygwb.util import window_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this should be unnecessary\n",
    "\n",
    "def pwelch_fft(data, segment_duration, do_overlap=True):\n",
    "    averaging_factor = int(segment_duration/data.dt.value)\n",
    "    if do_overlap:\n",
    "        seg_indices = np.arange(1, len(data),int(averaging_factor/2))\n",
    "        seg_indices = seg_indices[seg_indices <= len(data)+2-averaging_factor]\n",
    "    else: # NOT CHECKED\n",
    "        seg_indices = np.arange(1, len(data),averaging_factor)[0:-1]\n",
    "\n",
    "    averaged = data[0:len(seg_indices)].copy() # temporary spectrogram\n",
    "    kk = 0\n",
    "    for ii in (seg_indices-1):\n",
    "        averaged[kk] = data[ii:ii+11].mean(axis=0)\n",
    "        kk = kk +1\n",
    "    averaged.times = averaged.epoch.value*data.times.unit + (seg_indices-1)*data.dt\n",
    "    return np.real(averaged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate PSD all possible segments for detector 1\n",
    "base_HL.set_cross_and_power_spectral_density(frequency_resolution)\n",
    "\n",
    "avg_psd_1 = spectral.before_after_average(ifo_H1.psd_spectrogram, \n",
    "                            segment_duration, segment_duration)\n",
    "avg_psd_2 = spectral.before_after_average(ifo_L1.psd_spectrogram, \n",
    "                            segment_duration, segment_duration)\n",
    "stride = segment_duration - overlap\n",
    "csd_segment_offset = int(np.ceil(segment_duration / stride))\n",
    "\n",
    "csd = spectral.coarse_grain_spectrogram(2*base_HL.csd)[csd_segment_offset:-(csd_segment_offset+1) + 1]\n",
    "# factor of 2 here because...?\n",
    "\n",
    "segment_starttime = csd.times.value - (segment_duration / 2) # for later use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# initialise baseline - get ORF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if coarse_grain:\n",
    "    freqs = np.arange(0, len(stochastic_mat['gamma']))*frequency_resolution\n",
    "else:\n",
    "    freqs = avg_psd_1.yindex.value\n",
    "\n",
    "base_HL.set_frequencies(freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaF = freqs[1]-freqs[0]\n",
    "try:\n",
    "    assert abs(deltaF - frequency_resolution) < 1e-6 # within machine (floating point) precision\n",
    "except ValueError:  \n",
    "    print('Frequency resolution in PSD/CSD is different than requested.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### AIR: I STOPPED HERE ###########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Band limiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_band_cut = (freqs>=flow) & (freqs<=fhigh)\n",
    "freqs = freqs[freq_band_cut]\n",
    "naive_psd_1 = naive_psd_1.crop_frequencies(flow, fhigh+deltaF)\n",
    "naive_psd_2 = naive_psd_2.crop_frequencies(flow, fhigh+deltaF)\n",
    "avg_psd_1 = avg_psd_1.crop_frequencies(flow, fhigh+deltaF)\n",
    "avg_psd_2 = avg_psd_2.crop_frequencies(flow, fhigh+deltaF)\n",
    "csd = csd.crop_frequencies(flow, fhigh+deltaF)\n",
    "orf = orf[freq_band_cut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygwb.util import FrequencySeries\n",
    "from gwpy.spectrogram import Spectrogram\n",
    "cc = np.zeros((len(csd),len(freqs)),dtype=complex)\n",
    "for ii in range(len(csd)):\n",
    "    c = FrequencySeries(ifo1_fft_csd.yindex.value, 2*np.conj(ifo1_fft_csd[ii+2].value)* ifo2_fft_csd[ii+2].value)\n",
    "    # coarse grain\n",
    "    c_cg = c.coarse_grain(deltaF, flow, fhigh)\n",
    "    cc[ii,:] = c_cg.data\n",
    "csd_alt = Spectrogram(cc, times=csd.xindex.value, frequencies=csd.yindex.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygwb.util import window_factors\n",
    "cc = np.zeros((len(csd),len(freqs)),dtype=complex)\n",
    "cc[0,:] = stochastic_mat[\"rrCG\"][0].data\n",
    "cc[1,:] = stochastic_mat[\"rrCG\"][1].data\n",
    "cc[2,:] = stochastic_mat[\"rrCG\"][2].data\n",
    "csd = Spectrogram(cc, times=csd.xindex.value, frequencies=csd.yindex.value)\n",
    "w1w2bar, w1w2squaredbar, _, _ = window_factors(4096*192)\n",
    "const =  new_sample_rate / (w1w2bar * 4096*192)\n",
    "csd = 2* const * csd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate Y and sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygwb.constants import H0\n",
    "from pygwb.constants import speed_of_light\n",
    "from pygwb.util import window_factors\n",
    "\n",
    "# window factors\n",
    "w1w2bar, w1w2squaredbar, _, _ = window_factors(4096*192)\n",
    "\n",
    "def calculate_Yf_varf(freqs, csd, avg_psd_1, avg_psd_2, orf, fref, alpha,):    \n",
    "    S_alpha = 3 * H0**2 / (10 * np.pi**2) / freqs**3 * (freqs/fref)**alpha\n",
    "    Y_fs = np.real(csd)/(orf * S_alpha)\n",
    "    var_fs = 1 / (2 * segment_duration * (freqs[1]-freqs[0])) * avg_psd_1 * avg_psd_2 / (orf**2 * S_alpha**2)\n",
    "    var_fs = var_fs * w1w2squaredbar / w1w2bar ** 2\n",
    "    return Y_fs, var_fs\n",
    "\n",
    "def calculate_Yf_varf_from_stochastic(freqs, ccspec, sensint):\n",
    "    Y_fs_temp = np.zeros((len(ccspec),len(ccspec[0].data)),dtype='complex')\n",
    "    var_fs_temp = np.zeros((len(ccspec),len(ccspec[0].data)))\n",
    "    for ii in range(0, len(ccspec)):\n",
    "        var_fs_temp[ii,:] = 1/(sensint[ii].data.T*deltaF*segment_duration**2)\n",
    "        var_tot = 1/np.sum(1/var_fs_temp[ii,:])\n",
    "        Y_fs_temp[ii,:] = (2/var_tot) * ((ccspec[ii].data/segment_duration)/(sensint[ii].data.T*segment_duration**2))\n",
    "    return np.real(Y_fs_temp), var_fs_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Y_f and sigma_f of stochastic analysis for every segment\n",
    "Y_fs, var_fs = calculate_Yf_varf(freqs, csd.value, \n",
    "                                   avg_psd_1.value, \n",
    "                                   avg_psd_2.value, \n",
    "                                   orf, fref, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make final point estimate and error bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Andrew's code\n",
    "from pygwb import postprocessing\n",
    "from pygwb.util import calc_Y_sigma_from_Yf_varf\n",
    "Y_f_andrew, var_f_andrew = postprocessing.postprocessing_spectra(Y_fs.T, var_fs.T, tf-t0, segment_duration, deltaF, \n",
    "                                    1/new_sample_rate, number_cropped_seconds)\n",
    "Y_pyGWB_andrew, sigma_pyGWB_andrew = calc_Y_sigma_from_Yf_varf(Y_f_andrew, var_f_andrew, freqs, alpha, fref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Pat's code\n",
    "from pygwb import postprocessing_pat\n",
    "iso_job = postprocessing_pat.IsotropicJob(Y_fs, (var_fs)**0.5, segment_starttime, segment_duration, new_sample_rate, frequencies=freqs)\n",
    "Y_f = iso_job.combined_Y_spectrum\n",
    "var_f = iso_job.combined_sigma_spectrum**2\n",
    "Y_pyGWB, sigma_pyGWB = iso_job.calculate_broadband_statistics(0) # alpha = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Result from Andrews code: {0:g} +/- {1:g}\".format(Y_pyGWB_andrew, sigma_pyGWB_andrew))\n",
    "print(\"Result from Pats code: {0:g} +/- {1:g}\".format(Y_pyGWB, sigma_pyGWB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygwb.util import calc_bias\n",
    "\n",
    "def postprocess_Y_sigma(Y_fs, var_fs):\n",
    "    size = np.size(Y_fs, axis=0)\n",
    "    _, w1w2squaredbar, _, w1w2squaredovlbar = window_factors(192*4096)\n",
    "    k = (w1w2squaredovlbar / w1w2squaredbar)\n",
    "\n",
    "    # even/odd indices\n",
    "    evens = np.arange(0, size, 2)\n",
    "    odds = np.arange(1, size, 2)\n",
    "\n",
    "    X_even = np.nansum(Y_fs[evens] / var_fs[evens], axis=0)\n",
    "    GAMMA_even = np.nansum(var_fs[evens] ** -1, axis=0)\n",
    "    X_odd = np.nansum(Y_fs[odds] / var_fs[odds], axis=0)\n",
    "    GAMMA_odd = np.nansum(var_fs[odds] ** -1, axis=0)  \n",
    "    sigma2_oo = 1/np.nansum(GAMMA_odd)\n",
    "    sigma2_ee = 1/np.nansum(GAMMA_even)\n",
    "    sigma2_1 = 1/np.nansum(var_fs[0,:] ** -1)\n",
    "    sigma2_N = 1/np.nansum(var_fs[-1,:] ** -1)\n",
    "    sigma2IJ = (1/sigma2_oo + 1/sigma2_ee - (1/2) * (1/sigma2_1+1/sigma2_N))\n",
    "\n",
    "\n",
    "    Y_f_new = (X_odd * (1- (k/2) * sigma2_oo * sigma2IJ) + X_even * (1- (k/2) * sigma2_ee * sigma2IJ))/ (\n",
    "            GAMMA_even + GAMMA_odd - k * (GAMMA_even + GAMMA_odd - (1/2) * (1/var_fs[0,:] + 1/var_fs[-1,:])))\n",
    "\n",
    "    inv_var_f_new = (GAMMA_odd + GAMMA_even - k * (GAMMA_odd + GAMMA_even - (1/2) * (1/var_fs[0,:] + 1/var_fs[-1,:]))) / (\n",
    "            1- (k**2 /4) * sigma2_oo * sigma2_ee * sigma2IJ**2)\n",
    "    bias = calc_bias(segment_duration, deltaF, 1 / new_sample_rate)\n",
    "    var_f_new = (1 / inv_var_f_new) * bias**2\n",
    "    var_f_new[notch_freq] = np.inf\n",
    "    \n",
    "    return Y_f_new, var_f_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_f_new, var_f_new = postprocess_Y_sigma(Y_fs, var_fs)\n",
    "Y_f_new_alt, var_f_new_alt = postprocess_Y_sigma(Y_fs_alt, var_fs_alt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(stochastic_mat['freq'], Y_f_new/Y_f_matlab)\n",
    "plt.xlim(flow, fhigh)\n",
    "plt.ylabel('Y_f ratio')\n",
    "plt.ylim(-1e-4+1, 1e-4+1)\n",
    "plt.xlim(20,1726)\n",
    "#plt.yscale('linear')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(stochastic_mat['freq'], Y_f_new_alt/Y_f_matlab)\n",
    "plt.xlim(flow, fhigh)\n",
    "plt.ylabel('Y_f ratio')\n",
    "plt.ylim(0.99, 1.01)\n",
    "plt.xlim(20,1726)\n",
    "#plt.yscale('linear')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(freqs, np.sqrt(var_f_new)/np.real(stochastic_mat['sigma_ff']))\n",
    "plt.ylim(-1e-6+1, 1e-6+1)\n",
    "plt.xlim([flow, fhigh])\n",
    "plt.ylabel('sigma_f ratio')\n",
    "plt.xlim([20, 1726])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_maltab, sigma_matlab = calc_Y_sigma_from_Yf_varf(np.real(stochastic_mat['ptEst_ff']), stochastic_mat['sigma_ff']**2, freqs, alpha, fref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pyGWB_new, sigma_pyGWB_new = calc_Y_sigma_from_Yf_varf(Y_f_new, var_f_new, freqs, alpha, fref)\n",
    "Y_pyGWB_new_alt, sigma_pyGWB_new_alt = calc_Y_sigma_from_Yf_varf(Y_f_new_alt, var_f_new_alt, freqs, alpha, fref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Comparing point estimates')\n",
    "print('\\tstochastic.m: %e'%(Y_maltab))\n",
    "print('\\tpyGWB: %e'%(Y_pyGWB))\n",
    "print('\\t%% diff: %f%%'%(100*abs((Y_pyGWB-Y_maltab)/Y_maltab)))\n",
    "\n",
    "print('Comparing sigmas')\n",
    "print('\\tstochastic.m: %e'%(sigma_matlab))\n",
    "print('\\tpyGWB: %e'%(sigma_pyGWB))\n",
    "print('\\t%% diff: %f%%'%(100*abs((sigma_pyGWB-sigma_matlab)/sigma_matlab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Comparing point estimates')\n",
    "print('\\tstochastic.m: %e'%(Y_maltab))\n",
    "print('\\tpyGWB: %e'%(Y_pyGWB_new))\n",
    "print('\\t%% diff: %f%%'%(100*abs((Y_pyGWB_new-Y_maltab)/Y_maltab)))\n",
    "\n",
    "print('Comparing sigmas')\n",
    "print('\\tstochastic.m: %e'%(sigma_matlab))\n",
    "print('\\tpyGWB: %e'%(sigma_pyGWB_new))\n",
    "print('\\t%% diff: %f%%'%(100*abs((sigma_pyGWB_new-sigma_matlab)/sigma_matlab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Y_f and sigma_f of stochastic analysis for each segment\n",
    "for ii in range(0,3):\n",
    "    Y_seg, var_seg = calculate_Yf_varf(freqs, csd[0].value, \n",
    "                                   avg_psd_1[ii].value, \n",
    "                                   avg_psd_2[ii].value, \n",
    "                                   orf, fref, alpha)\n",
    "    Y_seg[notch_freq] = 0\n",
    "    var_seg[notch_freq] = 1e80 # some large number\n",
    "    Y_pyGWB_seg, sigma_pyGWB_seg = calc_Y_sigma_from_Yf_varf(Y_seg, var_seg, freqs, alpha, fref)\n",
    "    print(sigma_pyGWB_seg/stochastic_mat['ccSigma'][ii]*192)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
