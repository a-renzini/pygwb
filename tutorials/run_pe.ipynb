{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "735272f5-cacf-4c2a-9736-ac68eed33057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import bilby\n",
    "from scipy.io import loadmat\n",
    "from pygwb.pe import *\n",
    "from pygwb.baseline import Baseline\n",
    "import bilby.gw.detector as bilbydet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d34a2d-7312-48d4-a3ba-c697ffdef21b",
   "metadata": {},
   "source": [
    "# Parameter Estimation tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64aab35b-aa8d-4510-8ff2-9a44feaa7f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "#take e.g. O3\n",
    "frequencies, Y_HL, sigma_HL = np.loadtxt('/home/katarina.martinovic/o3_data/C_O3_HL.dat', unpack=True, usecols=(0,1,2))\n",
    "Y_HV, sigma_HV = np.loadtxt('/home/katarina.martinovic/o3_data/C_O3_HV.dat', unpack=True, usecols=(1,2))\n",
    "Y_LV, sigma_LV = np.loadtxt('/home/katarina.martinovic/o3_data/C_O3_LV.dat', unpack=True, usecols=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19909778-5594-40da-8379-cfb2a8003107",
   "metadata": {},
   "outputs": [],
   "source": [
    "#go up to 256 Hz\n",
    "idx=np.argmin(np.abs(frequencies-256))\n",
    "frequencies = frequencies[:idx]\n",
    "#cut all of the data for frequencies > 256 Hz\n",
    "sigma_HL = sigma_HL[:idx]\n",
    "Y_HL = Y_HL[:idx]\n",
    "sigma_HV = sigma_HV[:idx]\n",
    "Y_HV = Y_HV[:idx]\n",
    "sigma_LV = sigma_LV[:idx]\n",
    "Y_LV = Y_LV[:idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf1415fe-df6b-4752-ae9e-0b11f94710f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove infinities from sigma measurements(O3)\n",
    "inf_array=np.isinf(sigma_HL)\n",
    "not_inf_array = ~ inf_array\n",
    "sigma_HL = sigma_HL[not_inf_array]\n",
    "Y_HL=Y_HL[not_inf_array]\n",
    "sigma_HV = sigma_HV[not_inf_array]\n",
    "Y_HV=Y_HV[not_inf_array]\n",
    "sigma_LV = sigma_LV[not_inf_array]\n",
    "Y_LV=Y_LV[not_inf_array]\n",
    "frequencies=frequencies[not_inf_array]\n",
    "\n",
    "inf_array=np.isinf(sigma_HV)\n",
    "not_inf_array = ~ inf_array\n",
    "sigma_HL = sigma_HL[not_inf_array]\n",
    "Y_HL=Y_HL[not_inf_array]\n",
    "sigma_HV = sigma_HV[not_inf_array]\n",
    "Y_HV=Y_HV[not_inf_array]\n",
    "sigma_LV = sigma_LV[not_inf_array]\n",
    "Y_LV=Y_LV[not_inf_array]\n",
    "frequencies=frequencies[not_inf_array]\n",
    "\n",
    "inf_array=np.isinf(sigma_LV)\n",
    "not_inf_array = ~ inf_array\n",
    "sigma_HL = sigma_HL[not_inf_array]\n",
    "Y_HL=Y_HL[not_inf_array]\n",
    "sigma_HV = sigma_HV[not_inf_array]\n",
    "Y_HV=Y_HV[not_inf_array]\n",
    "sigma_LV = sigma_LV[not_inf_array]\n",
    "Y_LV=Y_LV[not_inf_array]\n",
    "frequencies=frequencies[not_inf_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15d4ee65-ff7b-4d1a-bd98-a651ae792dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arianna.renzini/PROJECTS/pygwb/pygwb/baseline.py:249: UserWarning: Neither baseline nor interferometer duration is set.\n",
      "  warnings.warn(\"Neither baseline nor interferometer duration is set.\")\n",
      "/home/arianna.renzini/PROJECTS/pygwb/pygwb/baseline.py:446: UserWarning: Neither baseline nor interferometer sampling_frequency is set.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "point_estimates = [Y_HL, Y_HV, Y_LV]\n",
    "sigmas = [sigma_HL, sigma_HV, sigma_LV]\n",
    "H1 = bilbydet.get_empty_interferometer('H1')\n",
    "L1 = bilbydet.get_empty_interferometer('L1')\n",
    "V1 = bilbydet.get_empty_interferometer('V1')\n",
    "\n",
    "HL = Baseline('H1L1', H1, L1)\n",
    "HV = Baseline('H1V1', H1, V1)\n",
    "LV = Baseline('L1V1', L1, V1)\n",
    "\n",
    "HL.frequencies = frequencies\n",
    "HV.frequencies = frequencies\n",
    "LV.frequencies = frequencies\n",
    "\n",
    "\n",
    "HL.point_estimate = Y_HL\n",
    "HL.sigma = sigma_HL\n",
    "HV.point_estimate = Y_HV\n",
    "HV.sigma = sigma_HV\n",
    "LV.point_estimate = Y_LV\n",
    "LV.sigma = sigma_LV\n",
    "\n",
    "#take the more conservative O3b calibration\n",
    "HL.calibration_epsilon = 0.148\n",
    "HV.calibration_epsilon = 0.123\n",
    "LV.calibration_epsilon = 0.108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "793457c0-266b-4419-97e5-7a450fad479d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Baseline' object has no attribute '_orf_polarization'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m###############################################\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m###############Testing pl##################\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m###############################################\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#choose pair likelihoods for the models you want to constrain with the data\u001b[39;00m\n\u001b[1;32m      6\u001b[0m kwargs_pl \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbaselines\u001b[39m\u001b[38;5;124m\"\u001b[39m:[HL,HV,LV], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfref\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m25\u001b[39m}\n\u001b[0;32m----> 7\u001b[0m model_pl \u001b[38;5;241m=\u001b[39m \u001b[43mPowerLawModel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs_pl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m priors_pl \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124momega_ref\u001b[39m\u001b[38;5;124m'\u001b[39m: bilby\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mprior\u001b[38;5;241m.\u001b[39mLogUniform(\u001b[38;5;241m1e-13\u001b[39m, \u001b[38;5;241m1e-5\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mOmega_\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mrm ref}$\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      9\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m: bilby\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mprior\u001b[38;5;241m.\u001b[39mGaussian(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3.5\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124malpha$\u001b[39m\u001b[38;5;124m'\u001b[39m)}\n\u001b[1;32m     10\u001b[0m hlv_pl\u001b[38;5;241m=\u001b[39mbilby\u001b[38;5;241m.\u001b[39mrun_sampler(likelihood\u001b[38;5;241m=\u001b[39mmodel_pl,priors\u001b[38;5;241m=\u001b[39mpriors_pl,sampler\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynesty\u001b[39m\u001b[38;5;124m'\u001b[39m, npoints\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, walks\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, npool\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, outdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./pe/\u001b[39m\u001b[38;5;124m'\u001b[39m,label\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhlv_pl\u001b[39m\u001b[38;5;124m'\u001b[39m, resume\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/PROJECTS/pygwb/pygwb/pe.py:139\u001b[0m, in \u001b[0;36mPowerLawModel.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfref must be supplied\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mPowerLawModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfref \u001b[38;5;241m=\u001b[39m fref\n",
      "File \u001b[0;32m~/PROJECTS/pygwb/pygwb/pe.py:43\u001b[0m, in \u001b[0;36mGWBModel.__init__\u001b[0;34m(self, baselines, model_name, polarizations)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bline \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbaselines:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolarizations[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 43\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morfs\u001b[38;5;241m.\u001b[39mappend(\u001b[43mbline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moverlap_reduction_function\u001b[49m)\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolarizations[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvector\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morfs\u001b[38;5;241m.\u001b[39mappend(bline\u001b[38;5;241m.\u001b[39mvector_overlap_reduction_function)\n",
      "File \u001b[0;32m~/PROJECTS/pygwb/pygwb/baseline.py:119\u001b[0m, in \u001b[0;36mBaseline.overlap_reduction_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moverlap_reduction_function\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;124;03m\"\"\"Overlap reduction function associated to this baseline, calculated for the requested polarisation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_orf_polarization\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensor_overlap_reduction_function\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_orf_polarization \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvector\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Baseline' object has no attribute '_orf_polarization'"
     ]
    }
   ],
   "source": [
    "###############################################\n",
    "###############Testing pl##################\n",
    "###############################################\n",
    "\n",
    "#choose pair likelihoods for the models you want to constrain with the data\n",
    "kwargs_pl = {\"baselines\":[HL,HV,LV], \"model_name\":'PL', \"fref\":25}\n",
    "model_pl = PowerLawModel(**kwargs_pl)\n",
    "priors_pl = {'omega_ref': bilby.core.prior.LogUniform(1e-13, 1e-5, '$\\\\Omega_{\\\\rm ref}$'),\n",
    "                        'alpha': bilby.core.prior.Gaussian(0, 3.5, '$\\\\alpha$')}\n",
    "hlv_pl=bilby.run_sampler(likelihood=model_pl,priors=priors_pl,sampler='dynesty', npoints=1000, walks=10, npool=10, outdir='./pe/',label= 'hlv_pl', resume=False)\n",
    "hlv_pl.plot_corner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a4b1dc-b6be-4529-b76f-4b46d82e09fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###############################################\n",
    "# ###############Testing bpl##################\n",
    "# ###############################################\n",
    "\n",
    "# kwargs_bpl = {\"baselines\": [HL, HV, LV], \"model_name\":'BPL'}\n",
    "# model_bpl = BrokenPowerLawModel(**kwargs_bpl)\n",
    "# priors_bpl = {'omega_ref': bilby.core.prior.LogUniform(1e-13, 1e-5, '$\\\\Omega_{\\\\rm ref}$'),\n",
    "#             'fbreak': bilby.core.prior.Uniform(1, 100,'$f_{\\\\rm break}$'),\n",
    "#             'alpha_1': bilby.core.prior.Gaussian(0, 3.5, '$\\\\alpha_1$'),\n",
    "#             'alpha_2': bilby.core.prior.Gaussian(0, 3.5, '$\\\\alpha_2$')}\n",
    "# hlv_bpl=bilby.run_sampler(likelihood=model_bpl,priors=priors_bpl,sampler='dynesty', npoints=1000, walks=10,npool=10,outdir='./',label= 'hlv_bpl', resume=False)\n",
    "# hlv_bpl.plot_corner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11564907-9612-4045-ba75-6c2024127ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "######### Testing triple_BPL##################\n",
    "###############################################\n",
    "\n",
    "# kwargs_triple_bpl = {\"baselines\":[HL,HV,LV],\"model_name\": 'TBPL'}\n",
    "# model_triple_bpl = TripleBrokenPowerLawModel(**kwargs_triple_bpl)\n",
    "# priors_triple_bpl = {'omega_ref': bilby.core.prior.LogUniform(1e-13, 1e-5, '$\\\\Omega_{\\\\rm ref}$'),\n",
    "#                        'alpha_1': bilby.core.prior.Gaussian(0, 3.5, '$\\\\alpha_1$'),\n",
    "#                       'alpha_2': bilby.core.prior.Gaussian(0, 3.5, '$\\\\alpha_2$'),\n",
    "#                        'alpha_3': bilby.core.prior.Gaussian(0, 3.5, '$\\\\alpha_3$'),\n",
    "#                      'fbreak1': bilby.core.prior.Uniform(1, 100,'$f_{\\\\rm break}^1$'), \n",
    "#                      'fbreak2': bilby.core.prior.Uniform(1, 100,'$f_{\\\\rm break}^2$')}\n",
    "# hlv_triple_bpl = bilby.run_sampler(likelihood=model_triple_bpl,priors=priors_triple_bpl,sampler='dynesty', npoints=1000, walks=10,npool=10,outdir='./',label= 'hlv_tbpl', resume=False)\n",
    "# hlv_triple_bpl.plot_corner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a417368d-acaf-448c-94cc-eb83226aacca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###############################################\n",
    "# ######### Testing Smooth Broken PL#############\n",
    "# ###############################################\n",
    "\n",
    "# kwargs_sbpl = {\"baselines\":[HL,HV,LV],\"model_name\": 'SBPL'}\n",
    "# model_sbpl = SmoothBrokenPowerLawModel(**kwargs_sbpl)\n",
    "# priors_sbpl = {'omega_ref': bilby.core.prior.LogUniform(1e-13, 1e-5, '$\\\\Omega_{\\\\rm ref}$'),\n",
    "#                   'fbreak': bilby.core.prior.Uniform(1, 256, '$f_{\\\\rm break}$'),\n",
    "#                         'alpha_1': bilby.core.prior.Gaussian(0, 3.5, '$\\\\alpha_1$'),\n",
    "#                        'alpha_2': bilby.core.prior.Gaussian(0, 3.5, '$\\\\alpha_2$'),\n",
    "#                         'delta': bilby.core.prior.Uniform(0, 8, '$\\\\Delta$')}\n",
    "# hlv_sbpl = bilby.run_sampler(likelihood=model_sbpl,priors=priors_sbpl,sampler='dynesty', npoints=1000, walks=10,npool=10,outdir='./',label= 'hlv_sbpl', resume=False)\n",
    "# hlv_sbpl.plot_corner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fbf451-0cd5-4584-9981-2ac8b0877aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###############################################\n",
    "# ###############Testing tvs pl##################\n",
    "# ###############################################\n",
    "\n",
    "# kwargs_pl_sv={\"baselines\":[HL, HV, LV], \"model_name\":'PL_SV', \"fref\":25, \"polarizations\":['scalar', 'vector']}\n",
    "# model_pl_sv = TVSPowerLawModel(**kwargs_pl_sv)\n",
    "# priors_pl_sv = {'omega_ref_scalar': bilby.core.prior.LogUniform(1e-13, 1e-5, '$\\\\Omega_{\\\\rm ref,s}$'),\n",
    "#                       'alpha_scalar': bilby.core.prior.Gaussian(0, 3.5, '$\\\\alpha_s$'),\n",
    "#           'omega_ref_vector': bilby.core.prior.LogUniform(1e-13, 1e-5, '$\\\\Omega_{\\\\rm ref,v}$'),\n",
    "#                       'alpha_vector': bilby.core.prior.Gaussian(0, 3.5, '$\\\\alpha_v$')}\n",
    "# hlv_pl_sv=bilby.run_sampler(likelihood=model_pl_sv,priors=priors_pl_sv,sampler='dynesty', npoints=1000, walks=10,npool=10,outdir='./',label= 'hlv_pl_sv', resume=False)\n",
    "# hlv_pl_sv.plot_corner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960f886e-6f52-4fbc-ab73-a8e5157cebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###############################################\n",
    "# ######### Testing Parity Violation PL 1 #######\n",
    "# ###############################################\n",
    "\n",
    "# kwargs_pl_pv = {\"baselines\":[HL, HV, LV],\"model_name\": 'PL_PV', 'fref': 25}\n",
    "# model_pl_pv = PVPowerLawModel(**kwargs_pl_pv)\n",
    "# priors_pl_pv = {'omega_ref': bilby.core.prior.LogUniform(1e-13, 1e-5, '$\\\\Omega_{\\\\rm ref}$'),\n",
    "#                        'alpha': bilby.core.prior.Gaussian(0, 3.5, '$\\\\alpha$'),\n",
    "#                        'Pi': bilby.core.prior.Uniform(-1,1,'$\\\\Pi$')}\n",
    "# hlv_pl_pv = bilby.run_sampler(likelihood=model_pl_pv,priors=priors_pl_pv,sampler='dynesty', npoints=1000, walks=10,npool=10,outdir='./',label= 'hlv_pl_pv', resume=False)\n",
    "# hlv_pl_pv.plot_corner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c5df52-668d-4405-aa86-bc61df991143",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "######## Testing Parity Violation PL 2 #######\n",
    "##############################################\n",
    "\n",
    "# kwargs_pv_pl_2 = {\"baselines\":[HL, HV, LV],\"model_name\": 'PL_PV_2', 'fref': 25}\n",
    "# model_pv_pl_2 = PVPowerLawModel2(**kwargs_pv_pl_2)\n",
    "# priors_pv_pl_2 = {'omega_ref': bilby.core.prior.LogUniform(1e-13, 1e-5, '$\\\\Omega_{\\\\rm ref}$'),\n",
    "#                      'alpha': bilby.core.prior.Gaussian(0, 3.5, '$\\\\alpha$'),\n",
    "#                        'beta': bilby.core.prior.Uniform(-2,0,'$\\\\beta$')}\n",
    "# hlv_pv_pl_2 = bilby.run_sampler(likelihood=model_pv_pl_2,priors=priors_pv_pl_2,sampler='dynesty', npoints=1000, walks=10,npool=10,outdir='./',label= 'hlv_pv_pl_2', resume=False)\n",
    "# hlv_pv_pl_2.plot_corner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fe3d29-528f-47e7-8fae-bf6952505cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##############################################\n",
    "# ######## Testing Schumann #######\n",
    "# ##############################################\n",
    "\n",
    "# frequencies, Y_HL, sigma_HL = np.loadtxt('C_O3_HL.dat', unpack=True, usecols=(0,1,2))\n",
    "# Y_HV, sigma_HV = np.loadtxt('C_O3_HV.dat', unpack=True, usecols=(1,2))\n",
    "# Y_LV, sigma_LV = np.loadtxt('C_O3_LV.dat', unpack=True, usecols=(1,2))\n",
    "# #load magnetic data\n",
    "# mag_data = loadmat('/home/patrick.meyers/git_repos/o3-isotropic-final/magnetic/magnetic_data_product_for_pe.mat')  \n",
    "# M_HL=(mag_data['hl']['ptEst_mag'][0][0].real)[0]\n",
    "# M_HV=(mag_data['hv']['ptEst_mag'][0][0].real)[0]\n",
    "# M_LV=(mag_data['lv']['ptEst_mag'][0][0].real)[0]\n",
    "\n",
    "# #go up to 99 Hz\n",
    "# idx=np.argmin(np.abs(frequencies-99))\n",
    "# frequencies = frequencies[:idx]\n",
    "# #cut all of the data for frequencies > 99 Hz\n",
    "# sigma_HL = sigma_HL[:idx]\n",
    "# Y_HL = Y_HL[:idx]\n",
    "# M_HL = M_HL[:idx]\n",
    "# sigma_HV = sigma_HV[:idx]\n",
    "# Y_HV = Y_HV[:idx]\n",
    "# M_HV = M_HV[:idx]\n",
    "# sigma_LV = sigma_LV[:idx]\n",
    "# Y_LV = Y_LV[:idx]\n",
    "# M_LV = M_LV[:idx]\n",
    "\n",
    "# #remove infinities from sigma measurements(O3a)\n",
    "# inf_array=np.isinf(sigma_HL)\n",
    "# not_inf_array = ~ inf_array\n",
    "# sigma_HL = sigma_HL[not_inf_array]\n",
    "# Y_HL=Y_HL[not_inf_array]\n",
    "# M_HL=M_HL[not_inf_array]\n",
    "# sigma_HV = sigma_HV[not_inf_array]\n",
    "# Y_HV=Y_HV[not_inf_array]\n",
    "# M_HV=M_HV[not_inf_array]\n",
    "# sigma_LV = sigma_LV[not_inf_array]\n",
    "# Y_LV=Y_LV[not_inf_array]\n",
    "# M_LV=M_LV[not_inf_array]\n",
    "# frequencies=frequencies[not_inf_array]\n",
    "\n",
    "# inf_array=np.isinf(sigma_HV)\n",
    "# not_inf_array = ~ inf_array\n",
    "# sigma_HL = sigma_HL[not_inf_array]\n",
    "# Y_HL=Y_HL[not_inf_array]\n",
    "# M_HL=M_HL[not_inf_array]\n",
    "# sigma_HV = sigma_HV[not_inf_array]\n",
    "# Y_HV=Y_HV[not_inf_array]\n",
    "# M_HV=M_HV[not_inf_array]\n",
    "# sigma_LV = sigma_LV[not_inf_array]\n",
    "# Y_LV=Y_LV[not_inf_array]\n",
    "# M_LV=M_LV[not_inf_array]\n",
    "# frequencies=frequencies[not_inf_array]\n",
    "\n",
    "# inf_array=np.isinf(sigma_LV)\n",
    "# not_inf_array = ~ inf_array\n",
    "# sigma_HL = sigma_HL[not_inf_array]\n",
    "# Y_HL=Y_HL[not_inf_array]\n",
    "# M_HL=M_HL[not_inf_array]\n",
    "# sigma_HV = sigma_HV[not_inf_array]\n",
    "# Y_HV=Y_HV[not_inf_array]\n",
    "# M_HV=M_HV[not_inf_array]\n",
    "# sigma_LV = sigma_LV[not_inf_array]\n",
    "# Y_LV=Y_LV[not_inf_array]\n",
    "# M_LV=M_LV[not_inf_array]\n",
    "# frequencies=frequencies[not_inf_array]\n",
    "\n",
    "# #remove nans from mag data\n",
    "# nan_array = np.isnan(M_HL)\n",
    "# not_nan_array = ~ nan_array\n",
    "# sigma_HL = sigma_HL[not_nan_array]\n",
    "# Y_HL=Y_HL[not_nan_array]\n",
    "# M_HL=M_HL[not_nan_array]\n",
    "# sigma_HV = sigma_HV[not_nan_array]\n",
    "# Y_HV=Y_HV[not_nan_array]\n",
    "# M_HV=M_HV[not_nan_array]\n",
    "# sigma_LV = sigma_LV[not_nan_array]\n",
    "# Y_LV=Y_LV[not_nan_array]\n",
    "# M_LV=M_LV[not_nan_array]\n",
    "# frequencies=frequencies[not_nan_array]\n",
    "\n",
    "# nan_array = np.isnan(M_HV)\n",
    "# not_nan_array = ~ nan_array\n",
    "# sigma_HL = sigma_HL[not_nan_array]\n",
    "# Y_HL=Y_HL[not_nan_array]\n",
    "# M_HL=M_HL[not_nan_array]\n",
    "# sigma_HV = sigma_HV[not_nan_array]\n",
    "# Y_HV=Y_HV[not_nan_array]\n",
    "# M_HV=M_HV[not_nan_array]\n",
    "# sigma_LV = sigma_LV[not_nan_array]\n",
    "# Y_LV=Y_LV[not_nan_array]\n",
    "# M_LV=M_LV[not_nan_array]\n",
    "# frequencies=frequencies[not_nan_array]\n",
    "\n",
    "# nan_array = np.isnan(M_LV)\n",
    "# not_nan_array = ~ nan_array\n",
    "# sigma_HL = sigma_HL[not_nan_array]\n",
    "# Y_HL=Y_HL[not_nan_array]\n",
    "# M_HL=M_HL[not_nan_array]\n",
    "# sigma_HV = sigma_HV[not_nan_array]\n",
    "# Y_HV=Y_HV[not_nan_array]\n",
    "# M_HV=M_HV[not_nan_array]\n",
    "# sigma_LV = sigma_LV[not_nan_array]\n",
    "# Y_LV=Y_LV[not_nan_array]\n",
    "# M_LV=M_LV[not_nan_array]\n",
    "# frequencies=frequencies[not_nan_array]\n",
    "\n",
    "# point_estimates = [Y_HL, Y_HV, Y_LV]\n",
    "# sigmas = [sigma_HL, sigma_HV, sigma_LV]\n",
    "# H1 = bilbydet.get_empty_interferometer('H1')\n",
    "# L1 = bilbydet.get_empty_interferometer('L1')\n",
    "# V1 = bilbydet.get_empty_interferometer('V1')\n",
    "\n",
    "# HL = Baseline('HL', H1, L1)\n",
    "# HV = Baseline('HV', H1, V1)\n",
    "# LV = Baseline('LV', L1, V1)\n",
    "\n",
    "# HL.frequencies = frequencies\n",
    "# HV.frequencies = frequencies\n",
    "# LV.frequencies = frequencies\n",
    "\n",
    "# HL.M_f = M_HL\n",
    "# HV.M_f = M_HV\n",
    "# LV.M_f = M_LV\n",
    "\n",
    "# HL.point_estimate = Y_HL\n",
    "# HL.sigma = sigma_HL\n",
    "# HV.point_estimate = Y_HV\n",
    "# HV.sigma = sigma_HV\n",
    "# LV.point_estimate = Y_LV\n",
    "# LV.sigma = sigma_LV\n",
    "\n",
    "# kwargs_schu={\"baselines\":[HL, HV, LV], \"model_name\":'Schu', \"polarizations\":['tensor']}\n",
    "# model_schu = SchumannModel(**kwargs_schu)\n",
    "# print(model_schu.ifos)\n",
    "# priors_schu = {'kappa_H': bilby.core.prior.LogUniform(0.01, 10, '$\\\\kappa_H$'),\n",
    "#             'kappa_L': bilby.core.prior.LogUniform(0.01, 10, '$\\\\kappa_L$'),\n",
    "#             'kappa_V': bilby.core.prior.LogUniform(0.01, 10, '$\\\\kappa_V$'),\n",
    "#             'beta_H': bilby.core.prior.Uniform(0.0, 12.0, '$\\\\beta_H$'),\n",
    "#             'beta_L': bilby.core.prior.Uniform(1.0, 10.0, '$\\\\beta_L$'),\n",
    "#            'beta_V': bilby.core.prior.Uniform(0.0, 7.0, '$\\\\beta_V$')}\n",
    "# hlv_schu=bilby.run_sampler(likelihood=model_schu,priors=priors_schu,sampler='dynesty', npoints=1000, walks=10,npool=10,outdir='./',label= 'hlv_schu', resume=False)\n",
    "# hlv_schu.plot_corner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a280782-907b-4a51-bafa-d99af3e56896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-2' coro=<Kernel.poll_control_queue() running at /home/arianna.renzini/.conda/envs/pygwb/lib/python3.8/site-packages/ipykernel/kernelbase.py:243> wait_for=<Future finished result=[<zmq.sugar.fr...x7f5596c7cb40>, <zmq.sugar.fr...x7f5596be2720>, <zmq.sugar.fr...x7f58763e1300>, <zmq.sugar.fr...x7f58680db250>, <zmq.sugar.fr...x7f58680db3b0>, <zmq.sugar.fr...x7f58680db300>, ...]> cb=[_chain_future.<locals>._call_set_state() at /home/arianna.renzini/.conda/envs/pygwb/lib/python3.8/asyncio/futures.py:367]>\n"
     ]
    }
   ],
   "source": [
    "# # ##############################################\n",
    "# # ######## Testing Schumann + pl #######\n",
    "# # ##############################################\n",
    "# #########combining models\n",
    "# #https://stackoverflow.com/questions/9667818/python-how-to-merge-two-class\n",
    "\n",
    "# #import data\n",
    "# #take e.g. O3\n",
    "# frequencies, Y_HL, sigma_HL = np.loadtxt('C_O3_HL.dat', unpack=True, usecols=(0,1,2))\n",
    "# Y_HV, sigma_HV = np.loadtxt('C_O3_HV.dat', unpack=True, usecols=(1,2))\n",
    "# Y_LV, sigma_LV = np.loadtxt('C_O3_LV.dat', unpack=True, usecols=(1,2))\n",
    "# #load magnetic data\n",
    "# mag_data = loadmat('/home/patrick.meyers/git_repos/o3-isotropic-final/magnetic/magnetic_data_product_for_pe.mat')  \n",
    "# M_HL=(mag_data['hl']['ptEst_mag'][0][0].real)[0]\n",
    "# M_HV=(mag_data['hv']['ptEst_mag'][0][0].real)[0]\n",
    "# M_LV=(mag_data['lv']['ptEst_mag'][0][0].real)[0]\n",
    "\n",
    "# #go up to 99 Hz\n",
    "# idx=np.argmin(np.abs(frequencies-99))\n",
    "# frequencies = frequencies[:idx]\n",
    "# #cut all of the data for frequencies > 99 Hz\n",
    "# sigma_HL = sigma_HL[:idx]\n",
    "# Y_HL = Y_HL[:idx]\n",
    "# M_HL = M_HL[:idx]\n",
    "# sigma_HV = sigma_HV[:idx]\n",
    "# Y_HV = Y_HV[:idx]\n",
    "# M_HV = M_HV[:idx]\n",
    "# sigma_LV = sigma_LV[:idx]\n",
    "# Y_LV = Y_LV[:idx]\n",
    "# M_LV = M_LV[:idx]\n",
    "\n",
    "# #remove infinities from sigma measurements(O3a)\n",
    "# inf_array=np.isinf(sigma_HL)\n",
    "# not_inf_array = ~ inf_array\n",
    "# sigma_HL = sigma_HL[not_inf_array]\n",
    "# Y_HL=Y_HL[not_inf_array]\n",
    "# M_HL=M_HL[not_inf_array]\n",
    "# sigma_HV = sigma_HV[not_inf_array]\n",
    "# Y_HV=Y_HV[not_inf_array]\n",
    "# M_HV=M_HV[not_inf_array]\n",
    "# sigma_LV = sigma_LV[not_inf_array]\n",
    "# Y_LV=Y_LV[not_inf_array]\n",
    "# M_LV=M_LV[not_inf_array]\n",
    "# frequencies=frequencies[not_inf_array]\n",
    "\n",
    "# inf_array=np.isinf(sigma_HV)\n",
    "# not_inf_array = ~ inf_array\n",
    "# sigma_HL = sigma_HL[not_inf_array]\n",
    "# Y_HL=Y_HL[not_inf_array]\n",
    "# M_HL=M_HL[not_inf_array]\n",
    "# sigma_HV = sigma_HV[not_inf_array]\n",
    "# Y_HV=Y_HV[not_inf_array]\n",
    "# M_HV=M_HV[not_inf_array]\n",
    "# sigma_LV = sigma_LV[not_inf_array]\n",
    "# Y_LV=Y_LV[not_inf_array]\n",
    "# M_LV=M_LV[not_inf_array]\n",
    "# frequencies=frequencies[not_inf_array]\n",
    "\n",
    "# inf_array=np.isinf(sigma_LV)\n",
    "# not_inf_array = ~ inf_array\n",
    "# sigma_HL = sigma_HL[not_inf_array]\n",
    "# Y_HL=Y_HL[not_inf_array]\n",
    "# M_HL=M_HL[not_inf_array]\n",
    "# sigma_HV = sigma_HV[not_inf_array]\n",
    "# Y_HV=Y_HV[not_inf_array]\n",
    "# M_HV=M_HV[not_inf_array]\n",
    "# sigma_LV = sigma_LV[not_inf_array]\n",
    "# Y_LV=Y_LV[not_inf_array]\n",
    "# M_LV=M_LV[not_inf_array]\n",
    "# frequencies=frequencies[not_inf_array]\n",
    "\n",
    "# #remove nans from mag data\n",
    "# nan_array = np.isnan(M_HL)\n",
    "# not_nan_array = ~ nan_array\n",
    "# sigma_HL = sigma_HL[not_nan_array]\n",
    "# Y_HL=Y_HL[not_nan_array]\n",
    "# M_HL=M_HL[not_nan_array]\n",
    "# sigma_HV = sigma_HV[not_nan_array]\n",
    "# Y_HV=Y_HV[not_nan_array]\n",
    "# M_HV=M_HV[not_nan_array]\n",
    "# sigma_LV = sigma_LV[not_nan_array]\n",
    "# Y_LV=Y_LV[not_nan_array]\n",
    "# M_LV=M_LV[not_nan_array]\n",
    "# frequencies=frequencies[not_nan_array]\n",
    "\n",
    "# nan_array = np.isnan(M_HV)\n",
    "# not_nan_array = ~ nan_array\n",
    "# sigma_HL = sigma_HL[not_nan_array]\n",
    "# Y_HL=Y_HL[not_nan_array]\n",
    "# M_HL=M_HL[not_nan_array]\n",
    "# sigma_HV = sigma_HV[not_nan_array]\n",
    "# Y_HV=Y_HV[not_nan_array]\n",
    "# M_HV=M_HV[not_nan_array]\n",
    "# sigma_LV = sigma_LV[not_nan_array]\n",
    "# Y_LV=Y_LV[not_nan_array]\n",
    "# M_LV=M_LV[not_nan_array]\n",
    "# frequencies=frequencies[not_nan_array]\n",
    "\n",
    "# nan_array = np.isnan(M_LV)\n",
    "# not_nan_array = ~ nan_array\n",
    "# sigma_HL = sigma_HL[not_nan_array]\n",
    "# Y_HL=Y_HL[not_nan_array]\n",
    "# M_HL=M_HL[not_nan_array]\n",
    "# sigma_HV = sigma_HV[not_nan_array]\n",
    "# Y_HV=Y_HV[not_nan_array]\n",
    "# M_HV=M_HV[not_nan_array]\n",
    "# sigma_LV = sigma_LV[not_nan_array]\n",
    "# Y_LV=Y_LV[not_nan_array]\n",
    "# M_LV=M_LV[not_nan_array]\n",
    "# frequencies=frequencies[not_nan_array]\n",
    "\n",
    "# point_estimates = [Y_HL, Y_HV, Y_LV]\n",
    "# sigmas = [sigma_HL, sigma_HV, sigma_LV]\n",
    "# H1 = bilbydet.get_empty_interferometer('H1')\n",
    "# L1 = bilbydet.get_empty_interferometer('L1')\n",
    "# V1 = bilbydet.get_empty_interferometer('V1')\n",
    "\n",
    "# HL = Baseline('HL', H1, L1)\n",
    "# HV = Baseline('HV', H1, V1)\n",
    "# LV = Baseline('LV', L1, V1)\n",
    "\n",
    "# HL.frequencies = frequencies\n",
    "# HV.frequencies = frequencies\n",
    "# LV.frequencies = frequencies\n",
    "\n",
    "# HL.M_f = M_HL\n",
    "# HV.M_f = M_HV\n",
    "# LV.M_f = M_LV\n",
    "\n",
    "# HL.point_estimate = Y_HL\n",
    "# HL.sigma = sigma_HL\n",
    "# HV.point_estimate = Y_HV\n",
    "# HV.sigma = sigma_HV\n",
    "# LV.point_estimate = Y_LV\n",
    "# LV.sigma = sigma_LV\n",
    "\n",
    "# gw_schu = type('gw_schu', (PowerLawModel,SchumannModel), dict(c='c'))\n",
    "# #instc = pl_schu('kwargs')\n",
    "# kwargs={\"baselines\":[HL, HV, LV], \"model_name\":'PL+Schu', \"polarizations\":['tensor'],\"fref\":25}\n",
    "# model = gw_schu(**kwargs)\n",
    "\n",
    "# priors= {'kappa_H': bilby.core.prior.LogUniform(0.01, 10, '$\\\\kappa_H$'),\n",
    "#             'kappa_L': bilby.core.prior.LogUniform(0.01, 10, '$\\\\kappa_L$'),\n",
    "#             'kappa_V': bilby.core.prior.LogUniform(0.01, 10, '$\\\\kappa_V$'),\n",
    "#             'beta_H': bilby.core.prior.Uniform(0.0, 12.0, '$\\\\beta_H$'),\n",
    "#             'beta_L': bilby.core.prior.Uniform(1.0, 10.0, '$\\\\beta_L$'),\n",
    "#            'beta_V': bilby.core.prior.Uniform(0.0, 7.0, '$\\\\beta_V$'),\n",
    "#             'omega_ref': bilby.core.prior.LogUniform(1e-13, 1e-5, '$\\\\Omega_{\\\\rm ref}$'),\n",
    "#              'alpha': bilby.core.prior.Gaussian(0, 3.5, '$\\\\alpha$')}\n",
    "# hlv_gw_schu=bilby.run_sampler(likelihood=model,priors=priors,sampler='dynesty', npoints=1000, walks=10,npool=10,outdir='./',label= 'hlv_gw_schu', resume=False)\n",
    "# hlv_gw_schu.plot_corner()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pygwb",
   "language": "python",
   "name": "pygwb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
